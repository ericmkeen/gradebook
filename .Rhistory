cruz$cohorts$all$sightings %>%
select(year, stratum, DateTime, OnEffort, Cruise, EffType, SwellHght, RainFog, Glare,
use, ObsStd, Bearing, Cue, Method, PerpDistKm, species, ss_tot, mixed, included) %>%
filter(year == 2020) %>%
filter(species %in% c('177', '277', '377', '077')) %>%
filter(stratum == 'WHICEAS') %>%
filter(included == TRUE,
EffType == 'S',
PerpDistKm <= 5.5)
cruz$cohorts$all$sightings %>%
select(year, stratum, DateTime, OnEffort, Cruise, EffType, SwellHght, RainFog, Glare,
use, ObsStd, Bearing, Cue, Method, PerpDistKm, species, ss_tot, mixed, included) %>%
filter(year == 2020) %>%
filter(species == '051') %>%
filter(stratum == 'WHICEAS') %>%
filter(EffType == 'S',
included == TRUE)
cruz$cohorts$all$sightings %>%
select(year, stratum, DateTime, OnEffort, Cruise, EffType, SwellHght, RainFog, Glare,
use, ObsStd, Bearing, Cue, Method, PerpDistKm, species, ss_tot, mixed, included) %>%
filter(year == 2020) %>%
filter(species == '059') %>%
filter(stratum == 'WHICEAS') %>%
filter(EffType == 'S')
cruz$cohorts$all$sightings %>%
select(year, stratum, DateTime, OnEffort, Cruise, EffType, SwellHght, RainFog, Glare,
use, ObsStd, Bearing, Cue, Method, PerpDistKm, species, ss_tot, mixed, included) %>%
filter(year == 2020) %>%
filter(species %in% c('078', '079', '098', '096')) %>%
filter(stratum == 'WHICEAS') %>%
filter(included == TRUE,
EffType == 'S',
PerpDistKm <= 5.5)
cruz$cohorts$all$sightings %>%
select(year, stratum, DateTime, OnEffort, Cruise, EffType, SwellHght, RainFog, Glare,
use, ObsStd, Bearing, Cue, Method, PerpDistKm, species, ss_tot, mixed, included) %>%
filter(year == 2020) %>%
filter(species == '059') %>%
filter(stratum == 'WHICEAS') %>%
filter(EffType == 'S')
das_file <- '../data/CenPac1986-2020_Final_alb.das'
das_inspector(das_file)
# Library packages
library(dplyr)
library(ggplot2)
library(readr)
library(tidyr)
library(gsheet)
library(leaflet)
library(sf)
# Q2: Read in the study area dataset
url <- 'https://raw.githubusercontent.com/ericmkeen/sewanee_esus/master/03_sequestration/nelson_polygon.csv'
urban_sewanee <- read_csv(url)
leaflet() %>%
addTiles() %>%
addPolygons(lng = urban_sewanee$lon,
lat = urban_sewanee$lat)
url <- 'https://raw.githubusercontent.com/ericmkeen/sewanee_esus/master/03_sequestration/nelson-sample-locations.csv'
sites <- read_csv(url)
leaflet() %>%
addTiles() %>%
addPolygons(lng = urban_sewanee$lon,
lat = urban_sewanee$lat) %>%
addCircleMarkers(lng = sites$lon,
lat = sites$lat)
nrow(sites)
url <- 'https://raw.githubusercontent.com/ericmkeen/sewanee_esus/master/03_sequestration/nelson_trees.csv'
trees <- read_csv(url)
nrow(trees)
trees %>%
group_by(plot) %>%
tally() %>%
summarize(mean_trees = mean(n, na.rm=TRUE),
sd_trees = sd(n),
min_trees = min(n),
max_trees = max(n))
species_counts <-
trees %>%
group_by(species) %>%
#tally()
summarize(n = n())
ggplot(species_counts,
aes(y = species,
x = n)) +
geom_col()
trees_fixed <-
trees %>%
mutate(dbh_fixed = dbh / pi) %>%
mutate(eric = 54)
tree_table <-
trees_fixed %>%
group_by(species) %>%
summarize(n = n(),
mean_dbh = mean(dbh_fixed),
sd_dbh = sd(dbh_fixed),
min_dbh = min(dbh_fixed),
max_dbh = max(dbh_fixed)) %>%
arrange(desc(n)) %>%
head(10)
# Stage 1: get the 6 largest species
top_six <-
tree_table %>%
filter(n > 4) %>%
arrange(desc(mean_dbh)) %>%
head(6) %>%
pull(species)
top_six
# Stage 2: filter trees_fixed to those species
top_six_data <-
trees_fixed %>%
filter(species %in% top_six)
# Stage 3: plot it
ggplot(top_six_data,
aes(x = species,
y = dbh_fixed)) +
geom_violin()
atleast_five <-
trees_fixed %>%
group_by(species) %>%
summarize(n = n(),
mean_dbh = mean(dbh_fixed)) %>%
arrange(desc(n)) %>%
filter(n >= 5) %>%
group_by(mean_dbh) %>%
arrange(desc(n))
#atleast_five <-
trees_fixed %>%
group_by(species) %>%
summarize(n = n(),
mean_dbh = mean(dbh_fixed)) %>%
arrange(desc(n)) %>%
filter(n >= 5) %>%
group_by(mean_dbh) %>%
arrange(desc(n))
#atleast_five <-
trees_fixed %>%
group_by(species) %>%
summarize(n = n(),
mean_dbh = mean(dbh_fixed)) %>%
arrange(desc(n)) %>%
filter(n >= 5) %>%
group_by(mean_dbh) %>%
arrange(desc(n)) %>%
head(1)
#atleast_five <-
trees_fixed %>%
group_by(species) %>%
summarize(n = n(),
mean_dbh = mean(dbh_fixed)) %>%
arrange(desc(n)) %>%
filter(n >= 5) %>%
group_by(mean_dbh) %>%
arrange(desc(mean_dbh)) %>%
head(1)
#atleast_five <-
trees_fixed %>%
group_by(species) %>%
summarize(n = n(),
mean_dbh = mean(dbh_fixed)) %>%
arrange(desc(n)) %>%
filter(n >= 5) %>%
#group_by(mean_dbh) %>%
arrange(desc(mean_dbh)) %>%
head(1)
tree_table %>%
filter(n >= 5) %>%
arrange(desc(mean_dbh)) %>%
head(1)
# Stage 1: get the 6 largest species
top_six <-
tree_table %>%
filter(n > 4) %>%
arrange(desc(mean_dbh)) %>%
head(6) %>%
pull(species)
top_six
top_six_data %>% head
ggplot(top_six_data,
aes(x = species,
y = dbh_fixed)) +
geom_violin()
# Stage 3: plot it
ggplot(top_six_data,
aes(x = species,
y = dbh_fixed)) +
geom_violin() +
geom_point()
# Stage 3: plot it
ggplot(top_six_data,
aes(x = species,
y = dbh_fixed)) +
geom_violin() +
geom_point(alpha = 0.3)
# Stage 3: plot it
ggplot(top_six_data,
aes(x = species,
y = dbh_fixed)) +
geom_violin() +
#geom_point(alpha = 0.3) +
geom_jitter()
# Stage 3: plot it
ggplot(top_six_data,
aes(x = species,
y = dbh_fixed)) +
geom_violin() +
#geom_point(alpha = 0.3) +
geom_jitter()
# Stage 3: plot it
ggplot(top_six_data,
aes(x = species,
y = dbh_fixed)) +
geom_violin() +
#geom_point(alpha = 0.3) +
geom_jitter(alpha = 0.3)
b0 = -2.54
b1 = 2.43
dhb = 50
dbh = 50
biomass_kg = exp(b0 + b1*log(dbh))
(biomass_kg = exp(b0 + b1*log(dbh)))
b0 <- -2.54
b1 <- 2.43
dbh <- 50
biomass_kg <- exp(b0 + b1*log(dbh))
(biomass_kg <- exp(b0 + b1*log(dbh)))
1:200
dbh <- 1:200
(biomass_kg <- exp(b0 + b1*log(dbh)))
predicted_biomass <-
data.frame(dbh = 1:200)
predicted_biomass %>% head
predicted_biomass <-
data.frame(dbh = 1:200) %>%
mutate(biomass_kg = exp(b0 + b1*log(dbh)))
predicted_biomass %>% head
ggplot(predicted_biomass,
aes(x = dbh,
y = biomass_kg)) +
geom_line()
library(gsheet)
url <- 'https://docs.google.com/spreadsheets/d/1mx-4kfU4j966ORpzuFO0DG_VMmuQ08NR_uIxddJGc1E/edit?usp=sharing'
coefficients <- gsheet2tbl(url)
View(coefficients)
dbh = 79
coefficients %>%
filter(species == 'white pine')
coefficients %>%
filter(species == 'white oak')
(biomass_kg <- exp(co_white_pine$b0 + co_white_pine$b1*log(dbh)))
dbh = 79
co_white_pine <-
coefficients %>%
filter(species == 'white pine')
(biomass_kg <- exp(co_white_pine$b0 + co_white_pine$b1*log(dbh)))
(biomass_kg <- exp(co_white_pine$b0 + co_white_pine$b1*log(dbh)))
co_white_oak <-
coefficients %>%
filter(species == 'white oak')
(biomass_kg <- exp(co_white_oak$b0 + co_white_oak$b1*log(dbh)))
trees_joined <- left_join(trees_fixed, coefficients)
trees_joined %>% View
trees_joined <-
trees_joined %>%
mutate(biomass_kg = exp(b0 + b1*log(dbh)))
trees_joined %>% View
trees_joined <- left_join(trees_fixed, coefficients)
trees_joined <-
trees_joined %>%
mutate(biomass_kg = exp(b0 + b1*log(dbh_fixed)))
# Library packages
library(dplyr)
library(ggplot2)
library(readr)
library(tidyr)
library(gsheet)
library(leaflet)
library(sf)
# Q2: Read in the study area dataset
url <- 'https://raw.githubusercontent.com/ericmkeen/sewanee_esus/master/03_sequestration/nelson_polygon.csv'
urban_sewanee <- read_csv(url)
# Q3: Map the study area
leaflet() %>%
addTiles() %>%
addPolygons(lng = urban_sewanee$lon,
lat = urban_sewanee$lat)
# Q4: Add sample locations
url <- 'https://raw.githubusercontent.com/ericmkeen/sewanee_esus/master/03_sequestration/nelson-sample-locations.csv'
sites <- read_csv(url)
leaflet() %>%
addTiles() %>%
addPolygons(lng = urban_sewanee$lon,
lat = urban_sewanee$lat) %>%
addCircleMarkers(lng = sites$lon,
lat = sites$lat)
# 5: How many sites?
nrow(sites)
# 6: How many trees were measured?
url <- 'https://raw.githubusercontent.com/ericmkeen/sewanee_esus/master/03_sequestration/nelson_trees.csv'
trees <- read_csv(url)
nrow(trees)
# Q7: How many trees were measured per plot
# Provide the mean, SD, min, and max trees measured per plot
trees %>%
group_by(plot) %>%
tally() %>%
summarize(mean_trees = mean(n, na.rm=TRUE),
sd_trees = sd(n),
min_trees = min(n),
max_trees = max(n))
# Q8: Plot the number of trees measured for each species
# Stage 1: modify my data
species_counts <-
trees %>%
group_by(species) %>%
#tally()
summarize(n = n())
# Stage 2: plot it
ggplot(species_counts,
aes(y = species,
x = n)) +
geom_col()
# Get to question 9
trees_fixed <-
trees %>%
mutate(dbh_fixed = dbh / pi) %>%
mutate(eric = 54)
# Question 10 Create a table summarizing dbh =======
# for the 10 most-measured species
tree_table <-
trees_fixed %>%
group_by(species) %>%
summarize(n = n(),
mean_dbh = mean(dbh_fixed),
sd_dbh = sd(dbh_fixed),
min_dbh = min(dbh_fixed),
max_dbh = max(dbh_fixed)) %>%
arrange(desc(n)) %>%
head(10)
# Question 11:
# Of the species with at least 5 measurements,
# which tree species was largest on average?
trees_fixed %>%
group_by(species) %>%
summarize(n = n(),
mean_dbh = mean(dbh_fixed)) %>%
arrange(desc(n)) %>%
filter(n >= 5) %>%
arrange(desc(mean_dbh)) %>%
head(1)
tree_table %>%
filter(n >= 5) %>%
arrange(desc(mean_dbh)) %>%
head(1)
# Question 12:
# Violin plot of DBH
# for 6 largest species with 5 measurements
# Stage 1: get the 6 largest species
top_six <-
tree_table %>%
filter(n > 4) %>%
arrange(desc(mean_dbh)) %>%
head(6) %>%
pull(species)
top_six
# Stage 2: filter trees_fixed to those species
top_six_data <-
trees_fixed %>%
filter(species %in% top_six)
top_six_data %>% head
# Stage 3: plot it
ggplot(top_six_data,
aes(x = species,
y = dbh_fixed)) +
geom_violin() +
#geom_point(alpha = 0.3) +
geom_jitter(alpha = 0.3)
#
# Calculating carbon storage ==================
biomass_kg = exp(b0 + b1*log(dbh))
# Question 13
# Biomass in kg for a white pine with dbh = 50cm?
b0 <- -2.54
b1 <- 2.43
dbh <- 50
(biomass_kg <- exp(b0 + b1*log(dbh)))
# Question 14
# Plot predicted biomass for white pine trees 1 cm to 200 cm
dbh <- 1:200
(biomass_kg <- exp(b0 + b1*log(dbh)))
predicted_biomass <-
data.frame(dbh = 1:200) %>%
mutate(biomass_kg = exp(b0 + b1*log(dbh)))
predicted_biomass %>% head
ggplot(predicted_biomass,
aes(x = dbh,
y = biomass_kg)) +
geom_line()
# Question 15
# Which type of forest gains more biomass per year?
# A forest of small trees, or a forest of large trees?
# Question 16
# All else is not equal!
# Biomass regression coefficients  ===================
# Question 17
# DBH = 79cm. More biomass if white pine or white oak?
library(gsheet)
url <- 'https://docs.google.com/spreadsheets/d/1mx-4kfU4j966ORpzuFO0DG_VMmuQ08NR_uIxddJGc1E/edit?usp=sharing'
coefficients <- gsheet2tbl(url)
dbh = 79
co_white_pine <-
coefficients %>%
filter(species == 'white pine')
(biomass_kg <- exp(co_white_pine$b0 + co_white_pine$b1*log(dbh)))
co_white_oak <-
coefficients %>%
filter(species == 'white oak')
(biomass_kg <- exp(co_white_oak$b0 + co_white_oak$b1*log(dbh)))
# Join the coefficients dataset to the trees dataset
trees_joined <- left_join(trees_fixed, coefficients)
trees_joined %>% View
# Question 18
# Add a new column, biomass_kg, to the trees_fixed dataset
trees_joined <-
trees_joined %>%
mutate(biomass_kg = exp(b0 + b1*log(dbh_fixed)))
trees_joined %>% View
oakpine <-
trees_joined %>%
filter(species %in% c('oak', 'pine')) %>%
group_by(species) %>%
summarize(mean_biomass_kg = mean(biomass_kg))
oakpine
1306 / 362
trees_joined %>%
filter(species %in% c('oak', 'pine')) %>%
group_by(species) %>%
summarize(mean_biomass_kg = mean(biomass_kg))
1306 / 362
trees_joined <-
trees_joined %>%
mutate(carbon_kg = biomass_kg/2)
trees_joined %>% View
trees_joined <-
trees_joined %>%
mutate(co2_kg = carbon_kg*3.67)
treees_joined %>%
group_by(species) %>%
summarize(total_co2 = sum(co2_kg, na.rm=TRUE))
trees_joined %>%
group_by(species) %>%
summarize(total_co2 = sum(co2_kg, na.rm=TRUE))
trees_joined %>%
group_by(plot) %>%
summarize(total_co2 = sum(co2_kg, na.rm=TRUE))
trees_joined %>%
group_by(plot) %>%
summarize(co2_per_plot = sum(co2_kg, na.rm=TRUE))
co2_per_plot <-
trees_joined %>%
group_by(plot) %>%
tally(co2_kg)
co2_per_plot
co2_per_plot <-
trees_joined %>%
group_by(plot) %>%
summarize(total_co2 = sum(co2_kg, na.rm=TRUE))
co2_per_plot
# Load package:
library(suRvey)
(dates <- c(paste0('2023-09-0',8:9),
paste0('2023-09-',10:22)))
(dates <- c(paste0('2023-09-0',8:9),
paste0('2023-09-',10:22)))
# Get survey overview
survey_overviews(dates)
survey_dates <- dates
survey_dates
# Loop through each date
if(verbose){message('Looping through each date ...')}
i=1
verbose <- TRUE
# Loop through each date
if(verbose){message('Looping through each date ...')}
i=1
surveys <- list()
for(i in 1:length(survey_dates)){
survey_date <- survey_dates[i]
if(verbose){message('--- ',survey_date)}
survi <- survey_overview(survey_date)
survi %>% names
if(!is.null(survi)){
surveys[[length(surveys)+1]] <- survi
}
}
# Combine into sepearate lists
surveys %>% length
surveys
# Loop through each date
if(verbose){message('Looping through each date ...')}
i=1
surveys <- list()
survey_date <- survey_dates[i]
if(verbose){message('--- ',survey_date)}
survi <- survey_overview(survey_date)
survi %>% names
setwd("~/Desktop/projects/suRvey/overview tests")
# Get survey overview
survey_overviews(dates)
# Get survey overview
survey_overviews(dates)$sighting_summary
# Get survey overview
survey_overviews(dates)$sighting_summary %>% View
